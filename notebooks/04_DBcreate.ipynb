{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d3ced83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaf966ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"departuresDBcreate\")\n",
    "        .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7154d59",
   "metadata": {},
   "source": [
    "## Creating SQL Databases & Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60cd28cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### First we'll create the database itself\n",
    "spark.sql(\"CREATE DATABASE learn_spark_db\")\n",
    "spark.sql(\"USE learn_spark_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404f84b",
   "metadata": {},
   "source": [
    "#### Creating a Managed Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc3635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Method 1: Issues a SQL statement. We'll use method 2 so commenting this out.\n",
    "#spark.sql(\"CREATE TABLE managed_us_delay_flights_tbl (date STRING, delay INT, distance INT, origin STRING, destination STRING)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1265619",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Method 2: Using the DataFrame API\n",
    "\n",
    "csv = \"C:/Users/sean.cornillie/Education/LearningSparkV2/Spark_Dev/datasets/departuredelays.csv\"\n",
    "schema = \"date STRING, delay INT, distance INT, origin STRING, destination STRING\"\n",
    "\n",
    "flights_df = spark.read.csv(csv, schema=schema)\n",
    "flights_df.write.saveAsTable(\"managed_us_delay_flights_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4bccf",
   "metadata": {},
   "source": [
    "#### Creating an Unmanaged Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0636cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(flights_df\n",
    "    .write\n",
    "    .option(\"path\", \"/tmp/data/us_flights_delay\")\n",
    "    .saveAsTable(\"us_delay_flights_tbl\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee00d0a",
   "metadata": {},
   "source": [
    "## Temporary Views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873704fe",
   "metadata": {},
   "source": [
    "Temporary views in Spark SQL are session-scoped and will disappear if the session that creates it terminates. If we want to have a temporary view that is shared among all sessions and keep alive until the Spark application terminates, we can create a global temporary view."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa5316c",
   "metadata": {},
   "source": [
    "#### Creating Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b806439",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating Views: Can be done within dataframe API:\n",
    "\n",
    "df_sfo = spark.sql(\"\"\"SELECT date, delay, origin\n",
    "                      FROM us_delay_flights_tbl WHERE origin = 'SFO'\n",
    "                      \"\"\")\n",
    "\n",
    "df_jfk = spark.sql(\"\"\"SELECT date, delay, origin\n",
    "                      FROM us_delay_flights_tbl WHERE origin = 'JFK'\n",
    "                      \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6797a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a global temp view\n",
    "df_sfo.createOrReplaceGlobalTempView(\"us_origin_airport_SFO_global_tmp_view\")\n",
    "\n",
    "### Create a temp view\n",
    "df_jfk.createOrReplaceTempView(\"us_origin_airport_JFK_tmp_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be2418f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------+\n",
      "|    date|delay|origin|\n",
      "+--------+-----+------+\n",
      "|01011250|   55|   SFO|\n",
      "|01012230|    0|   SFO|\n",
      "|01010705|   -7|   SFO|\n",
      "|01010620|   -3|   SFO|\n",
      "|01010915|   -3|   SFO|\n",
      "+--------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Can select from these views with standard SQL.\n",
    "### For global we must add prefix 'global_temp.'\n",
    "spark.sql(\"SELECT * FROM global_temp.us_origin_airport_SFO_global_tmp_view\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6ed4a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------+\n",
      "|    date|delay|origin|\n",
      "+--------+-----+------+\n",
      "|02010900|   -1|   JFK|\n",
      "|02011200|   -5|   JFK|\n",
      "|02011030|   -6|   JFK|\n",
      "|02011900|   -1|   JFK|\n",
      "|02011700|   -3|   JFK|\n",
      "+--------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### For regular view we can drop the global_temp.\n",
    "spark.sql(\"SELECT * FROM us_origin_airport_JFK_tmp_view\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9accb979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------+\n",
      "|    date|delay|origin|\n",
      "+--------+-----+------+\n",
      "|02010900|   -1|   JFK|\n",
      "|02011200|   -5|   JFK|\n",
      "|02011030|   -6|   JFK|\n",
      "|02011900|   -1|   JFK|\n",
      "|02011700|   -3|   JFK|\n",
      "+--------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Can also use the dataframe API to select:\n",
    "spark.read.table(\"us_origin_airport_JFK_tmp_view\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863b8767",
   "metadata": {},
   "source": [
    "#### Dropping Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfe9983e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Drop just like we would a table\n",
    "###DROP VIEW IF EXISTS us_origin_airport_SFO_global_tmp_view;\n",
    "###DROP VIEW IF EXISTS us_origin_airport_JFK_tmp_view\n",
    "\n",
    "spark.catalog.dropGlobalTempView(\"us_origin_airport_SFO_global_tmp_view\")\n",
    "spark.catalog.dropTempView(\"us_origin_airport_JFK_tmp_view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f615e71",
   "metadata": {},
   "source": [
    "To re-iterate global temp vs temp views: Temp views are tied to a single spark session, while, a Global Temp view is visible across multiple spark sessions within a spark application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e69c33",
   "metadata": {},
   "source": [
    "## Viewing Medata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7634c694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Database(name='default', description='default database', locationUri='file:/C:/Users/sean.cornillie/Education/LearningSparkV2/Spark_Dev/notebooks/spark-warehouse'),\n",
       " Database(name='learn_spark_db', description='', locationUri='file:/C:/Users/sean.cornillie/Education/LearningSparkV2/Spark_Dev/notebooks/spark-warehouse/learn_spark_db.db')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listDatabases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7b1c69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='managed_us_delay_flights_tbl', database='learn_spark_db', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='us_delay_flights_tbl', database='learn_spark_db', description=None, tableType='EXTERNAL', isTemporary=False)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2030ef36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column(name='date', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='delay', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='distance', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='origin', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='destination', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listColumns(\"us_delay_flights_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94439c46",
   "metadata": {},
   "source": [
    "## Reading Tables into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1c1acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Two methods: Use SQL or the Datframe API\n",
    "us_flights_df = spark.sql(\"SELECT * FROM us_delay_flights_tbl\")\n",
    "us_flights_df2 = spark.table(\"us_delay_flights_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e30a215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+\n",
      "|    date|delay|distance|origin|destination|\n",
      "+--------+-----+--------+------+-----------+\n",
      "|01201755|    0|     449|   ORF|        ATL|\n",
      "|01201610|   52|     449|   ORF|        ATL|\n",
      "|01201441|    0|     449|   ORF|        ATL|\n",
      "|01211755|  -15|     449|   ORF|        ATL|\n",
      "|01210941|   -5|     449|   ORF|        ATL|\n",
      "+--------+-----+--------+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_flights_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91a3712f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+\n",
      "|    date|delay|distance|origin|destination|\n",
      "+--------+-----+--------+------+-----------+\n",
      "|01201755|    0|     449|   ORF|        ATL|\n",
      "|01201610|   52|     449|   ORF|        ATL|\n",
      "|01201441|    0|     449|   ORF|        ATL|\n",
      "|01211755|  -15|     449|   ORF|        ATL|\n",
      "|01210941|   -5|     449|   ORF|        ATL|\n",
      "+--------+-----+--------+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_flights_df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1365484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
