{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d12dc558",
   "metadata": {},
   "source": [
    "# Data Sources for DataFrames and SQL Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8f0a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34344e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"departuresDFreadwrite\")\n",
    "        .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "862f25b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"C:/Users/sean.cornillie/Education/LearningSparkV2/databricks-datasets/flights/summary-data/parquet/2010-summary.parquet\"\n",
    "csv_file = \"C:/Users/sean.cornillie/Education/LearningSparkV2/databricks-datasets/flights/summary-data/csv/*\"\n",
    "json_file = \"C:/Users/sean.cornillie/Education/LearningSparkV2/databricks-datasets/flights/summary-data/json/*\"\n",
    "avro_file = \"C:/Users/sean.cornillie/Education/LearningSparkV2/databricks-datasets/flights/summary-data/avro/*\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ea4d81",
   "metadata": {},
   "source": [
    "## DataFrame Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b993efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parquet: Read in the folder with all of the partial files.\n",
    "df = spark.read.format(\"parquet\").load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0928c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parquet is default format so we can drop the format in this case. Will produce identical df.\n",
    "df2 = spark.read.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e79cc55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CSV\n",
    "### Can immediately see how much nicer it is to deal with parquets that contain saved metadata.\n",
    "df3 = (spark.read.format(\"csv\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"mode\", \"PERMISSIVE\")\n",
    "    .load(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dab7505",
   "metadata": {},
   "outputs": [],
   "source": [
    "### JSON\n",
    "df4 = spark.read.format(\"json\").load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fafc98c",
   "metadata": {},
   "source": [
    "## DataFrame Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32f2d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example:\n",
    "location = \"C:/Users/sean.cornillie/Education/LearningSparkV2/Spark_Dev/datasets/2010-summary.parquet\"\n",
    "df.write.format(\"parquet\").mode(\"overwrite\").save(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eba8fd",
   "metadata": {},
   "source": [
    "## Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cf2ef1",
   "metadata": {},
   "source": [
    "#### Write DataFrames to Spark SQL Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88edc343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").option(\"path\", \"/tmp/data/us_flights_delay2\").saveAsTable(\"us_delay_flights_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b1e193a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM us_delay_flights_tbl\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d44e07",
   "metadata": {},
   "source": [
    "#### Write DataFrames to parquet files (as in above example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a9f2b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.write.format(\"parquet\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"compression\", \"snappy\")\n",
    "    .save(\"/tmp/data/us_flights_delay2/df_parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a2bc5",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a907e",
   "metadata": {},
   "source": [
    "#### Read JSON file into a DataFrame and Spark SQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f11dfce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = spark.read.format(\"json\").load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "009ddbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.write.mode(\"overwrite\").option(\"path\", \"/tmp/data/us_flights_delay2\").saveAsTable(\"us_delay_flights_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "462b85f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM us_delay_flights_tbl\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9bedf3",
   "metadata": {},
   "source": [
    "#### Write DataFrames to JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e35c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.write.format(\"json\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"compression\", \"snappy\")\n",
    "    .save(\"/tmp/data/us_flights_delay2/df_json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a7a200",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69656a1",
   "metadata": {},
   "source": [
    "#### Read CSV file into DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a03b2bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count INT\"\n",
    "\n",
    "df3 = (spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .schema(schema)\n",
    "    .option(\"mode\", \"FAILFAST\") # Exit if any errors\n",
    "    .option(\"nullValue\", \"\")    # Replace any null data with quotes\n",
    "    .load(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1858a000",
   "metadata": {},
   "source": [
    "#### Read into Spark SQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "30c45cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.write.mode(\"overwrite\").option(\"path\", \"/tmp/data/us_flights_delay2\").saveAsTable(\"us_delay_flights_tbl\")\n",
    "spark.sql(\"SELECT * FROM us_delay_flights_tbl\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a0ca0",
   "metadata": {},
   "source": [
    "#### Write to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1723ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"csv\").mode(\"overwrite\").save(\"/tmp/data/us_flights_delay2/df_csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b248f13",
   "metadata": {},
   "source": [
    "## Images\n",
    "Supports deep learning & ML frameworks such as TensorFlow & PyTorch, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a85283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a2594d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"C:/Users/sean.cornillie/Education/LearningSparkV2/databricks-datasets/cctvVideos/train_images/\"\n",
    "\n",
    "images_df = spark.read.format(\"image\").load(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "642380a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0a7f93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------+----+-----+\n",
      "|height|width|nChannels|mode|label|\n",
      "+------+-----+---------+----+-----+\n",
      "|288   |384  |3        |16  |0    |\n",
      "|288   |384  |3        |16  |1    |\n",
      "|288   |384  |3        |16  |0    |\n",
      "|288   |384  |3        |16  |0    |\n",
      "|288   |384  |3        |16  |0    |\n",
      "+------+-----+---------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images_df.select(\"image.height\", \"image.width\", \"image.nChannels\", \"image.mode\",\n",
    "\"label\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32c9758",
   "metadata": {},
   "source": [
    "## Binary Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f81d7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+--------------------+-----+\n",
      "|                path|    modificationTime|length|             content|label|\n",
      "+--------------------+--------------------+------+--------------------+-----+\n",
      "|file:/C:/Users/se...|2022-11-25 10:01:...| 55037|[FF D8 FF E0 00 1...|    0|\n",
      "|file:/C:/Users/se...|2022-11-25 10:01:...| 54634|[FF D8 FF E0 00 1...|    1|\n",
      "|file:/C:/Users/se...|2022-11-25 10:01:...| 54624|[FF D8 FF E0 00 1...|    0|\n",
      "|file:/C:/Users/se...|2022-11-25 10:01:...| 54505|[FF D8 FF E0 00 1...|    0|\n",
      "|file:/C:/Users/se...|2022-11-25 10:01:...| 54475|[FF D8 FF E0 00 1...|    0|\n",
      "+--------------------+--------------------+------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"C:/Users/sean.cornillie/Education/LearningSparkV2/databricks-datasets/cctvVideos/train_images/\"\n",
    "\n",
    "binary_files_df = (spark.read.format(\"binaryFile\")\n",
    "                      .option(\"pathGlobFilter\", \"*.jpg\")\n",
    "                      .load(path))\n",
    "\n",
    "binary_files_df.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
